import joblib
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
import json
from scipy.sparse import csr_matrix

def match_tfidf_with_joblib(
    docs_joblib_path: str,
    queries_joblib_path: str,
    output_path: str = "tfidf_results_batch.json",
    top_k: int = 100,
    batch_size_queries: int = 100
):
    print("ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ (tfidf_matrix + doc_ids)...")
    docs_data = joblib.load(docs_joblib_path)
    doc_ids = docs_data["doc_ids"]
    tfidf_docs: csr_matrix = docs_data["tfidf_matrix"]

    print("ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª (query_tfidf_matrix + query_ids)...")
    queries_data = joblib.load(queries_joblib_path)

    # Ø§Ø®ØªÙŠØ§Ø± Ù…ØµÙÙˆÙØ© Ø§Ù„Ù€ tfidf Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø³Ù„ÙŠÙ…Ø©
    if "query_tfidf_matrix" in queries_data:
        tfidf_queries = queries_data["query_tfidf_matrix"]
    elif "tfidf_matrix" in queries_data:
        tfidf_queries = queries_data["tfidf_matrix"]
    elif "queries_tfidf_matrix" in queries_data:
        tfidf_queries = queries_data["queries_tfidf_matrix"]
    else:
        raise ValueError("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ØµÙÙˆÙØ© tfidf ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª.")

    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù€ query_ids Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø³Ù„ÙŠÙ…Ø©
    if "query_ids" in queries_data:
        query_ids = queries_data["query_ids"]
    elif "doc_ids" in queries_data:
        query_ids = queries_data["doc_ids"]
    else:
        raise ValueError("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ 'query_ids' Ø£Ùˆ 'doc_ids' ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª.")

    num_queries = tfidf_queries.shape[0]
    print(f"ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª: {num_queries}, Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚: {tfidf_docs.shape[0]}")

    results = {}

    for start in tqdm(range(0, num_queries, batch_size_queries), desc="ğŸ”„ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¯ÙØ¹Ø§Øª Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª"):
        end = min(start + batch_size_queries, num_queries)
        batch_queries = tfidf_queries[start:end]

        # Ø­Ø³Ø§Ø¨ Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ (batch_size_queries x num_docs)
        sim_matrix = cosine_similarity(batch_queries, tfidf_docs)

        for i, query_idx in enumerate(range(start, end)):
            sims = sim_matrix[i]
            top_indices = np.argpartition(sims, -top_k)[-top_k:]
            top_scores = sims[top_indices]
            sorted_idx = top_indices[np.argsort(-top_scores)]

            results[query_ids[query_idx]] = [
                (doc_ids[idx], float(sims[idx])) for idx in sorted_idx
            ]

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"âœ… ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙŠ {output_path}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…Ø¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TF-IDF")
    parser.add_argument("--docs_joblib_path", type=str, required=True, help="Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ (joblib)")
    parser.add_argument("--queries_joblib_path", type=str, required=True, help="Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª (joblib)")
    parser.add_argument("--output_path", type=str, default="tfidf_results_batch.json", help="Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (json)")
    parser.add_argument("--top_k", type=int, default=100, help="Ø¹Ø¯Ø¯ Ø£Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø±Ø§Ø¯ Ø¥Ø±Ø¬Ø§Ø¹Ù‡Ø§")
    parser.add_argument("--batch_size_queries", type=int, default=100, help="Ø­Ø¬Ù… Ø¯ÙØ¹Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª")

    args = parser.parse_args()

    match_tfidf_with_joblib(
        docs_joblib_path=args.docs_joblib_path,
        queries_joblib_path=args.queries_joblib_path,
        output_path=args.output_path,
        top_k=args.top_k,
        batch_size_queries=args.batch_size_queries
    )
