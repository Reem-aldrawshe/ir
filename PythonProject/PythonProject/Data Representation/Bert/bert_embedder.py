# bert_embedder.py

import os
import joblib
import torch
from tqdm import tqdm
from pymongo import MongoClient
from transformers import AutoTokenizer, AutoModel

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModel.from_pretrained(MODEL_NAME)
model.eval()

# Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

def get_bert_embedding(text):
    """ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ø¥Ù„Ù‰ ØªÙ…Ø«ÙŠÙ„ BERT Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CLS token"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    inputs = {key: val.to(device) for key, val in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token
    return embeddings.squeeze().cpu().numpy()

def process_bert_from_mongodb(dataset_name, collection_name):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© MongoDB"""
    print(f"ğŸš€ Processing BERT embeddings from MongoDB collection: {collection_name}...")

    # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    client = MongoClient("mongodb://localhost:27017/")
    db = client["ir_project"]
    collection = db[collection_name]

    # Ø¬Ù„Ø¨ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
    documents = list(collection.find({}, {"_id": 0, "doc_id": 1, "original_text": 1}))
    documents = [doc for doc in documents if doc.get("original_text", "").strip()]

    if not documents:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØµÙˆØµ Ø£ØµÙ„ÙŠØ© Ù…ØªØ§Ø­Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
        return

    doc_ids = [doc["doc_id"] for doc in documents]
    texts = [doc["original_text"] for doc in documents]

    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª
    all_embeddings = []
    for text in tqdm(texts, desc="Embedding"):
        emb = get_bert_embedding(text)
        all_embeddings.append(emb)

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    embedding_data = {
        "doc_ids": doc_ids,
        "embeddings_matrix": all_embeddings,
        "model_name": MODEL_NAME
    }

    save_path = os.path.join(dataset_name.replace("/", os.sep), "doc")
    os.makedirs(save_path, exist_ok=True)
    save_file = os.path.join(save_path, "bert_embedding.joblib")
    joblib.dump(embedding_data, save_file)

    print(f"âœ… BERT embeddings saved to: {save_file}")

# Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
if __name__ == "__main__":
    # Ø£Ù…Ø«Ù„Ø© ØªÙ†ÙÙŠØ° Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
    process_bert_from_mongodb("beir/quora/test", "documents_quora_test")
